# State-of-the-Art Techniques for Image Classification

PyTorch implementations of state-of-the-art computer vision algorithms utilizing attention

[ResNet (Vanilla)](https://github.com/tescala2/sota_classification/blob/main/models/resnet/vanilla.py) - "Deep Residual Learning for Image Recognition" - <https://arxiv.org/abs/1512.03385> \
ResNet (CBAM) - "CBAM: Convolutional Block Attention Module" - <https://arxiv.org/abs/1807.06521> \
ResNet (SASA) - "Stand-Alone Self-Attention in Vision Models" - <https://arxiv.org/abs/1906.05909v1> \
ResNet (SAAA) - "Stand-Alone Axial-Attention for Panoptic Segmentation" - <https://arxiv.org/abs/2003.07853> \
ResNet (AACN) - "Attention Augmented Convolutional Networks" - <https://arxiv.org/abs/1904.09925> \
ViT - "An Image is Worth 16x16 Words" - <https://arxiv.org/abs/2010.11929> \
MaxViT - "MaxViT: Multi-Axis Vision Transformer" - <https://arxiv.org/abs/2204.01697> \
Next-ViT - "Next-ViT: Next Generation Vision Transformer for Efficient Deployment in Realistic Industrial Scenarios" - <https://arxiv.org/abs/2207.05501> \
SwinT - "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows" - <https://arxiv.org/abs/2103.14030> \
SwinT V2 - "Swin Transformer V2: Scaling Up Capacity and Resolution" - <https://arxiv.org/abs/2111.09883> \
ConvNeXt - "A ConvNet for the 2020s" - <https://arxiv.org/abs/2201.03545> \
